{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 2\n",
    "MAKESUBMISSION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000 test digits.\n",
      "28000 valid test digits.\n",
      "42000 train digits.\n",
      "42000 valid train digits.\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv('data/test.csv')\n",
    "print(f'{X_test.shape[0]} test digits.')\n",
    "X_test = X_test.dropna()\n",
    "print(f'{X_test.shape[0]} valid test digits.')\n",
    "X_test = np.reshape(X_test.values, (X_test.shape[0], 28, 28))\n",
    "\n",
    "data_train = pd.read_csv('data/train.csv')\n",
    "print(f'{data_train.shape[0]} train digits.')\n",
    "data_train = data_train.dropna()\n",
    "print(f'{data_train.shape[0]} valid train digits.')\n",
    "X = data_train.drop(columns=['label'])\n",
    "X = np.reshape(X.values, (X.shape[0], 28, 28))\n",
    "y = pd.get_dummies(data_train['label'])\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0,\n",
    "    patience=20,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(28,28,1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 13:29:21.848405: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - ETA: 0s - loss: 0.4266 - accuracy: 0.9312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 13:29:36.505639: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 17s 14ms/step - loss: 0.4266 - accuracy: 0.9312 - val_loss: 0.0981 - val_accuracy: 0.9706\n",
      "Epoch 2/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0714 - accuracy: 0.9783 - val_loss: 0.0570 - val_accuracy: 0.9825\n",
      "Epoch 3/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0486 - accuracy: 0.9854 - val_loss: 0.0599 - val_accuracy: 0.9808\n",
      "Epoch 4/200\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0471 - accuracy: 0.9853 - val_loss: 0.0489 - val_accuracy: 0.9863\n",
      "Epoch 5/200\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0383 - accuracy: 0.9884 - val_loss: 0.0529 - val_accuracy: 0.9831\n",
      "Epoch 6/200\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0316 - accuracy: 0.9896 - val_loss: 0.0486 - val_accuracy: 0.9856\n",
      "Epoch 7/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0356 - accuracy: 0.9893 - val_loss: 0.0537 - val_accuracy: 0.9850\n",
      "Epoch 8/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.0673 - val_accuracy: 0.9830\n",
      "Epoch 9/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0295 - accuracy: 0.9911 - val_loss: 0.0523 - val_accuracy: 0.9873\n",
      "Epoch 10/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.0490 - val_accuracy: 0.9876\n",
      "Epoch 11/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.0524 - val_accuracy: 0.9882\n",
      "Epoch 12/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.0615 - val_accuracy: 0.9845\n",
      "Epoch 13/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0236 - accuracy: 0.9935 - val_loss: 0.0441 - val_accuracy: 0.9905\n",
      "Epoch 14/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0182 - accuracy: 0.9950 - val_loss: 0.0680 - val_accuracy: 0.9861\n",
      "Epoch 15/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0572 - val_accuracy: 0.9890\n",
      "Epoch 16/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0173 - accuracy: 0.9956 - val_loss: 0.0607 - val_accuracy: 0.9863\n",
      "Epoch 17/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.0592 - val_accuracy: 0.9887\n",
      "Epoch 18/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0220 - accuracy: 0.9948 - val_loss: 0.0917 - val_accuracy: 0.9820\n",
      "Epoch 19/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 0.0795 - val_accuracy: 0.9876\n",
      "Epoch 20/200\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 0.0987 - val_accuracy: 0.9874\n",
      "Epoch 21/200\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.1158 - val_accuracy: 0.9856\n",
      "Epoch 22/200\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0221 - accuracy: 0.9947 - val_loss: 0.0901 - val_accuracy: 0.9862\n",
      "Epoch 23/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.0919 - val_accuracy: 0.9855\n",
      "Epoch 24/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0201 - accuracy: 0.9952 - val_loss: 0.0795 - val_accuracy: 0.9862\n",
      "Epoch 25/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.0779 - val_accuracy: 0.9877\n",
      "Epoch 26/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0173 - accuracy: 0.9960 - val_loss: 0.0842 - val_accuracy: 0.9862\n",
      "Epoch 27/200\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0152 - accuracy: 0.9965 - val_loss: 0.1660 - val_accuracy: 0.9798\n",
      "Epoch 28/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0211 - accuracy: 0.9960 - val_loss: 0.1344 - val_accuracy: 0.9857\n",
      "Epoch 29/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.1260 - val_accuracy: 0.9839\n",
      "Epoch 30/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0159 - accuracy: 0.9968 - val_loss: 0.0904 - val_accuracy: 0.9875\n",
      "Epoch 31/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.1433 - val_accuracy: 0.9851\n",
      "Epoch 32/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.1213 - val_accuracy: 0.9880\n",
      "Epoch 33/200\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0167 - accuracy: 0.9963 - val_loss: 0.1300 - val_accuracy: 0.9861\n",
      "INFO:tensorflow:Assets written to: assets/model_2/assets\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "model.save(f'assets/model_{VERSION}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 13:38:59.526837: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict(X_test)\n",
    "y_test = np.round(y_test)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test = y_test.idxmax(axis=1)\n",
    "\n",
    "if MAKESUBMISSION:\n",
    "    submission = pd.DataFrame(columns=['ImageId', 'Label'])\n",
    "    submission['ImageId'] = np.arange(1,28001)\n",
    "    submission['Label'] = y_test\n",
    "    submission.to_csv(f'submission_{VERSION}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ae7ae13804f56b6812076ff88d4c743516b7c995d69dd5984882be015e04ad2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
